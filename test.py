import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from torchvision import transforms
from tqdm import tqdm # å¯¼å…¥tqdmç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡

# å¯¼å…¥MONAIçš„æ ¸å¿ƒç»„ä»¶
from generative.networks.nets import DiffusionModelUNet
from generative.networks.schedulers import DDPMScheduler

# --- 1. å‚æ•°è®¾ç½® ---
clean_image_path = r"F:\MONAI\train_g_data\ll\ground_truth_train_000_slice_001.png"
model_path = r"F:\MONAI\ldm\output\final_model.pth"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# å›¾åƒå’Œå™ªå£°å‚æ•°
IMG_SIZE = 176
noise_step_t = 10  # æˆ‘ä»¬å°†ä»è¿™ä¸ªæ—¶é—´æ­¥å¼€å§‹å»å™ª
total_train_timesteps = 1000

# --- 2. åŠ è½½æ‚¨è®­ç»ƒå¥½çš„DDPM (U-Net) æ¨¡å‹ ---
model = DiffusionModelUNet(
    spatial_dims=2,
    in_channels=1,
    out_channels=1,
    num_channels=(32, 64, 128,),
    attention_levels=(False, True, False),
    num_res_blocks=2,
    num_head_channels=32
)

model.load_state_dict(torch.load(model_path, map_location=device))
model.to(device)
model.eval()
print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")

# --- 3. åˆ›å»ºDDPMè°ƒåº¦å™¨ ---
scheduler = DDPMScheduler(
    num_train_timesteps=total_train_timesteps,
    beta_start=0.0015,
    beta_end=0.0205,
    schedule="scaled_linear_beta"
)
# vvvvvvvvvvvvvvvvvvvv   ã€æ–°å¢ã€‘è®¾ç½®è°ƒåº¦å™¨çš„æ—¶é—´æ­¥é•¿   vvvvvvvvvvvvvvvvvvvv
# è¿™ä¼šç”Ÿæˆä¸€ä¸ªä»999åˆ°0çš„åºåˆ—ï¼Œä¾›æˆ‘ä»¬åç»­è¿­ä»£ä½¿ç”¨
scheduler.set_timesteps(num_inference_steps=total_train_timesteps)
# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
print("âœ… è°ƒåº¦å™¨åˆ›å»ºæˆåŠŸï¼")

# --- 4. åŠ è½½å¹¶é¢„å¤„ç†åŸå§‹å›¾åƒ ---
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

try:
    original_image_pil = Image.open(clean_image_path)
    original_image_tensor = transform(original_image_pil).unsqueeze(0).to(device)
    print(f"âœ… åŸå§‹å›¾åƒåŠ è½½æˆåŠŸ: {clean_image_path}")
except FileNotFoundError:
    print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°åŸå§‹å›¾åƒæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼š{clean_image_path}")
    exit()

# --- 5. æ‰‹åŠ¨æ·»åŠ å™ªå£° (å‰å‘è¿‡ç¨‹) ---
noise = torch.randn_like(original_image_tensor)
add_noise_timesteps = torch.tensor([noise_step_t], device=device).long()
noisy_image_tensor = scheduler.add_noise(
    original_samples=original_image_tensor, noise=noise, timesteps=add_noise_timesteps
)
print(f"âœ… å·²å‘å›¾åƒæ·»åŠ  t={noise_step_t} çš„å™ªå£°ã€‚")


# --- 6. ä½¿ç”¨æ¨¡å‹è¿›è¡Œã€å¤šæ­¥ã€‘å»å™ª (é€†å‘è¿‡ç¨‹) ---
# vvvvvvvvvvvvvvvvvvvvvv   ã€å·²ä¿®æ”¹ä¸ºå¾ªç¯å»å™ªã€‘   vvvvvvvvvvvvvvvvvvvvvv
# ä»æˆ‘ä»¬åŠ å™ªåçš„å›¾ç‰‡å¼€å§‹ï¼Œä½œä¸ºå»å™ªçš„èµ·ç‚¹
denoising_image_tensor = noisy_image_tensor

# ç­›é€‰å‡ºä» t=500 å¼€å§‹åˆ° t=0 çš„æ‰€æœ‰æ—¶é—´æ­¥
timesteps_to_iterate = scheduler.timesteps[total_train_timesteps - noise_step_t:]

print(f"ğŸš€ å¼€å§‹ä» t={noise_step_t} è¿›è¡Œ {len(timesteps_to_iterate)} æ­¥å»å™ª...")

with torch.no_grad():
    # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡
    for t in tqdm(timesteps_to_iterate):
        # å°†æ—¶é—´æ­¥tè½¬æ¢ä¸ºå¼ é‡
        timestep_tensor = torch.tensor([t], device=device).long()
        
        # 1. é¢„æµ‹å™ªå£°
        predicted_noise = model(x=denoising_image_tensor, timesteps=timestep_tensor)
        
        # 2. è®¡ç®—ä¸Šä¸€æ­¥çš„å›¾åƒ (å»å™ª)
        denoising_output = scheduler.step(
            model_output=predicted_noise,
            timestep=t,
            sample=denoising_image_tensor
        )
        
        # 3. æ›´æ–°å›¾åƒï¼Œç”¨äºä¸‹ä¸€æ¬¡è¿­ä»£
        denoising_image_tensor = denoising_output[0]

# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
print("âœ… å·²å®Œæˆå¤šæ­¥å»å™ªã€‚")


# --- 7. æ˜¾ç¤ºç»“æœ ---
def tensor_to_pil(tensor):
    tensor = (tensor.clamp(-1, 1) + 1) / 2
    tensor = tensor.detach().cpu().squeeze()
    img_np = tensor.numpy()
    img = Image.fromarray((img_np * 255).astype(np.uint8))
    return img

fig, axes = plt.subplots(1, 3, figsize=(18, 6))

axes[0].imshow(tensor_to_pil(original_image_tensor), cmap='gray')
axes[0].set_title('Original Clean Image', fontsize=16)
axes[0].axis('off')

axes[1].imshow(tensor_to_pil(noisy_image_tensor), cmap='gray')
axes[1].set_title(f'Noisy Image (Start at t={noise_step_t})', fontsize=16)
axes[1].axis('off')

axes[2].imshow(tensor_to_pil(denoising_image_tensor), cmap='gray')
axes[2].set_title(f'Denoised Image (After {len(timesteps_to_iterate)} Steps)', fontsize=16)
axes[2].axis('off')

plt.tight_layout()
plt.show()
